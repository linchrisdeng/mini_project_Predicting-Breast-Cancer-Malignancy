---
title: "Predicting Breast Cancer Malignancy Using Data Mining Algorithms"
author: "Lin_Deng"
output:
  html_document:
    css: style.css
    theme: cosmo
    toc: yes
    toc_depth: 2
    toc_float: yes
  ioslides_presentation: default
  pdf_document: default
  date: "March 06, 2018"
  fontsize: 12pt

---
```{r, warning=F, message=F}
library(tidyverse)
library(ISLR)
library(rpart)
library(partykit)
library(randomForest)
library(gbm)
library(leaps)
library(MASS)
library(class)
library(boot)
library(rpart.plot)
```
```{r}

```
![](F:/2018_spring_semester_master/IE_5561_Data Driven Decision/Assignment/Project_1/snipaste_20180306_003831.png)

# I. Introduction & Background
Today, in the USA, about one in eight women has a risk of suffering from breast cancer over their life time.
Hence we need to dig out the relevant variables that can predict malignant tumor.

This data can be found on [UC Irvine Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). 

This dataset contains:

Attribute Information:

- ID number
- Diagnosis (M = malignant, B = benign)

Ten real-valued features are computed for each cell nucleus:

- radius (mean of distances from center to points on the perimeter)
- texture (standard deviation of gray-scale values) 
- perimeter
- area
- smoothness (local variation in radius lengths) 
- compactness (perimeter^2 / area - 1.0)
- concavity (severity of concave portions of the contour) 
- concave points (number of concave portions of the contour)
- symmetry 
- fractal dimension ("coastline approximation" - 1)

# II. Tidy Data
## 2.1. Import data
```{r}
bc <- read.csv("F:/2018_spring_semester_master/IE_5561_Data Driven Decision/Assignment/Project_1/breast-cancer-wisconsin-data/data.csv")
str(bc)
```
## 2.2. Tidy data
```{r}
bc$id <- NULL # remove unrelated variable
bc <- Filter(function(x) (length(unique(x)) > 1), bc) # remove variable only contains NA data
str(bc)
table(bc$diagnosis) #benign: 357, #malignant:212
```
# III.  Description & Basic Visualization

```{r, fig.width=5,fig.height=5, warning=F, message=F}
library(scales)

pie <- data.frame(group = c("Benign", "malignant"),
                  value = c(357/569, 212/569))

ggplot(pie, aes(x="", y = value, fill = group)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y", start = 0) + 
  geom_text(aes(y = value/3 + c(0, cumsum(value)[-length(value)]), label = c(percent(0.3726), percent(0.6274))), size = 5) + theme_light()
```

In 569 cases, 62.7% are Benign tumor, 37.3% are malignant tumor.

Here are desity plots of each variables.

```{r, fig.width=10,fig.height=11}
gather(bc, x, variables, radius_mean:fractal_dimension_worst) %>%
  ggplot(aes(x =variables, color = diagnosis, fill = diagnosis)) + geom_density(aes(color = diagnosis, fill = diagnosis), alpha = 0.5) + 
  facet_wrap(~x, scales = "free", ncol = 5)
```



# IV. Logistic Regression & Features Selection
## 4.1 Logistic Regression
### 4.1.1 Split data to training & test data

```{r}
set.seed(6)
index <- sample(1:nrow(bc), round(0.7*nrow(bc))) # 70% are training data
training <- bc[index, ]
test <- bc[-index,]
```

### 4.1.2 Fit logistic regression model

In the beginning I used total data to fit logistics regression

```{r, warning=F}
fit.logit <- glm(diagnosis~., data = training, family = "binomial")
summary(fit.logit)

pre1 <- predict(fit.logit, test, type = "response")

# set threshold = 0.3
pred.logit <- ifelse(pre1 < 0.3, "B", "M")
table(test$diagnosis, pred.logit)

1 - mean(test$diagnosis != pred.logit)

```

Prediction accuracy of logistic regression is 95.322%.

The accuracy is pretty good however, when I came back to see the outcome of the "summary", the p-value and standard error is too large. 

Hence I need to check correlations between these variables

## 4.2 Feature Selection
```{r, fig.width=10,fig.height=11, warning=F, message=F}
library(corrplot)
corrplot(cor(bc[-1]), method = "square")
```

There are many dark blue squares mentioned these variables are high correlated.

I should remove them and refit the model

```{r, warning=F}
library(caret)

highcor <- findCorrelation(cor(training[,-1]),cutoff = 0.6)

training.1 <- training[,-c(highcor + 1)]
test.1 <- test[, -c(highcor + 1)]
```


Refit logistic regression

```{r, warning=F}
fit.logit.1 <- glm(diagnosis~., data = training.1, family = "binomial")
summary(fit.logit.1)

corrplot(cor(training.1[-1]), method = "square")
```

We may find this model looks better

Let's prediction by using new logistic regression

```{r}
pre2 <- predict(fit.logit.1, test.1, type = "response")

# set threshold = 0.3
pred.logit.1 <- ifelse(pre2 < 0.3, "B", "M")
table(test.1$diagnosis, pred.logit.1)

1 - mean(test.1$diagnosis != pred.logit.1)
```

The prediction accuracy is 95.322%

# V. Prediction Models & Machine Learning Algorithms

## 5.1. k-Nearest Neighbour Classification
### 5.1.1 Split the data and label (diagnosis)
```{r}
set.seed(6)
train_label <- training[,1]
train_data <- training[, 2:31]

test_label <- test[,1]
test_data <- test[, 2:31]
```


### 5.1.2 Find optimal k-value of KNN
```{r}
# find the optimal k
k = 0
g = 1
ii = 0
for (i in 1:20) {
  pred.knn = knn(train_data, test_data, train_label, k = i)
  k = mean(pred.knn != test_label)
  if (k < g){
    g = k
    ii = i
  }
}
pred.knn <- knn(train_data, test_data, train_label, k = ii)

ii # means k value
(tab = table(pred.knn, test_label))
1-g # prediction accuracy
```

Prediction accuracy of KNN is 96.491%

## 5.2. k-Fold Cross Validation

For k = 10
```{r}
bc1 <- bc

bc1$diagnosis <- ifelse(bc1$diagnosis == "B", 1, 0)

glm.fit <- glm(diagnosis~., data = bc1)

cv.error.10 <- cv.glm(bc1, glm.fit, K = 10)$delta[1]

1 - cv.error.10
```

Prediction Accuracy of k-Fold Cross Validation is 93.795%

## 5.3. Trees
### 5.3.1 Build a plot a rpart tree
```{r}
cfit <- rpart(diagnosis~., data = training)
plot(as.party(cfit))
rpart.plot(cfit)
```

### 5.3.2 Make prediction 

Base on the ouput we don't need to prune this tree.

Hence I directly make the prediction of classification

```{r}
set.seed(69)
pred.cfit<- predict(cfit, test, type = "class")

table(test_label, pred.cfit)

# get accuracy
1 - mean(pred.cfit != test_label)
```

The accuray of classification tree is 94.152%

## 5.4. Randomforest

### 5.4.1 Prediction Model

Randomforest with 1000 trees

```{r}
set.seed(6)

rf <- randomForest(diagnosis~., data = training, ntree = 1000)
rf

# make prediction
pred.rf <- predict(rf, test)

# get accuracy
1 - mean(pred.rf != test$diagnosis)

plot(rf, main = "Error rate for Random Forest")
```

From the line Error rate graph, "1000 trees" is good to use.

The prediction accuracy of randomforest is 97.661%

### 5.4.2 Importance Visualization
```{r, fig.width=5,fig.height=6}
importance <- data.frame(importance(rf))

ggplot(importance, aes(x = reorder(rownames(importance), MeanDecreaseGini), y = MeanDecreaseGini)) + 
  geom_bar(stat = "identity" , aes(color = MeanDecreaseGini, fill = MeanDecreaseGini)) + 
  coord_flip() +
  labs(x= "Variables") 

```

From the Importance histogram, "concave.points_worst", "perimeter_worst", "radium_worst", "area_worst" and "concave.points_mean" are the 5 most important variables.

## 5.5. Boosting

```{r}
set.seed(6)
training.2 <- bc1[index, ]
test.2 <- bc1[-index, ]
boost <- gbm(diagnosis~., data = training.2, distribution = "bernoulli", n.trees = 1000, 
               interaction.depth = 1, shrinkage = 0.001)

pred.boost <- predict(boost, test.2, n.trees = 1000, type = "response")

# get MSE
mean((pred.boost - test.2$diagnosis)^2)

# get prediction accuracy
pred.boost <- ifelse(pred.boost >0.5, "B", "M")
1 - mean(pred.boost != test$diagnosis)
```

The prediction of Boosting is 94.152%

# Conclusion

After making prediction of 6 ML & Classification methods.

We can make a plot to compare them directly. 
```{r, warning=F}
library(ggthemes)

## accuracy plot for logistic regression
s <- matrix(0, nrow = length(test_label), ncol = 2)
s[,1] <- 1:length(test_label)
s[,2] <- ifelse(test_label == pred.logit.1, 1, 0)
for (i in 2:length(test_label)){
  s[i,2] = s[i-1,2] + s[i,2]
}
s[,2] = s[,2]/s[,1]
s.1 <- data.frame(s)
colnames(s.1) <- c("num", "accuracy")
g1 <- ggplot(s.1) + geom_path(aes(x = num, y = accuracy), color = "orange", size = 1)

## accuracy plot for KNN
s <- matrix(0, nrow = length(test_label), ncol = 2)
s[,1] <- 1:length(test_label)
s[,2] <- ifelse(test_label == pred.knn, 1, 0)
for (i in 2:length(test_label)){
  s[i,2] = s[i-1,2] + s[i,2]
}
s[,2] = s[,2]/s[,1]
s.2 <- data.frame(s)
colnames(s.2) <- c("num", "accuracy")
g2 <- g1 + geom_path(data = s.2, aes(x = num, y = accuracy), color = "royalblue", size = 1) 

## accuracy plot for TREE
s <- matrix(0, nrow = length(test_label), ncol = 2)
s[,1] <- 1:length(test_label)
s[,2] <- ifelse(test_label == pred.cfit, 1, 0)
for (i in 2:length(test_label)){
  s[i,2] = s[i-1,2] + s[i,2]
}
s[,2] = s[,2]/s[,1]
s.3 <- data.frame(s)
colnames(s.3) <- c("num", "accuracy")
g3 <- g2 + geom_path(data = s.3, aes(x = num, y = accuracy), color = "green", size = 1)


# accuracy plot for Random Forest
s <- matrix(0, nrow = length(test_label), ncol = 2)
s[,1] <- 1:length(test_label)
s[,2] <- ifelse(test_label == pred.rf, 1, 0)
for (i in 2:length(test_label)){
  s[i,2] = s[i-1,2] + s[i,2]
}
s[,2] = s[,2]/s[,1]
s.4 <- data.frame(s)
colnames(s.4) <- c("num", "accuracy")
g4 <- g3 + geom_path(data = s.4, aes(x = num, y = accuracy), color = "purple", size = 1)

## accuract plot for Boosting
s <- matrix(0, nrow = length(test_label), ncol = 2)
s[,1] <- 1:length(test_label)
s[,2] <- ifelse(test_label == pred.boost, 1, 0)
for (i in 2:length(test_label)){
  s[i,2] = s[i-1,2] + s[i,2]
}
s[,2] = s[,2]/s[,1]
s.5 <- data.frame(s)
colnames(s.5) <- c("num", "accuracy")
g5 <- g4 + geom_path(data = s.5, aes(x = num, y = accuracy), color = "black", size = 1) + theme_economist() + scale_colour_economist()

g5
```

Base on the final accuracy plot, we can find accuracy ranking of this models in training Breast Cancer data, 

- 1. Random Forest (97.661%)
- 2. k-Nearest Neighbor (96.491%)
- 3. Logistic Regression (95.322%)
- 4. Trees (94.152%)
- 5. Boosting (94.152%)
- 6. 10-fold Cross Validation (93.696%)

# Improvement

- Feature selection is required for any data analysis work and there are many methods we can use e.g. AIC, BIC, "Pearson" Correlation Coefficient;
- It's better to read related "dictionary" of your data, try to understand variables and make a comparably good formula by yourself.
- Visualization is pretty important to do data analysis.
